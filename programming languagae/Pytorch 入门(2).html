<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.24" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.94" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Pytorch 入门(2)","image":["https://vip.123pan.cn/1844935313/obsidian/20251014224728382.png","https://vip.123pan.cn/1844935313/obsidian/20251014224924676.png","https://vip.123pan.cn/1844935313/obsidian/20251014224958375.png","https://vip.123pan.cn/1844935313/obsidian/20251014225051167.png","https://vip.123pan.cn/1844935313/obsidian/20251015203201267.png","https://vip.123pan.cn/1844935313/obsidian/20251015203535035.png","https://vip.123pan.cn/1844935313/obsidian/20251101095651999.png","https://vip.123pan.cn/1844935313/obsidian/20251101100158825.png","https://vip.123pan.cn/1844935313/obsidian/20251101100354469.png","https://vip.123pan.cn/1844935313/obsidian/20251101100809508.png","https://vip.123pan.cn/1844935313/obsidian/20251101143912603.png","https://vip.123pan.cn/1844935313/obsidian/20251101155736341.png"],"datePublished":"2025-10-14T00:00:00.000Z","dateModified":"2025-11-16T07:10:09.000Z","author":[{"@type":"Person","name":"庸碌无常","url":"https://pluinyiasnhg.top"}]}</script><meta property="og:url" content="https://pluinyiasnhg.top/programming%20languagae/Pytorch%20%E5%85%A5%E9%97%A8(2).html"><meta property="og:site_name" content="庸碌无常的博客"><meta property="og:title" content="Pytorch 入门(2)"><meta property="og:description" content="学习尚硅谷的 NLP 教程。"><meta property="og:type" content="article"><meta property="og:image" content="https://vip.123pan.cn/1844935313/obsidian/20251014224728382.png"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-11-16T07:10:09.000Z"><meta property="article:tag" content="尚硅谷"><meta property="article:tag" content="Pytorch"><meta property="article:published_time" content="2025-10-14T00:00:00.000Z"><meta property="article:modified_time" content="2025-11-16T07:10:09.000Z"><title>Pytorch 入门(2) | 庸碌无常的博客</title><meta name="description" content="学习尚硅谷的 NLP 教程。">
    <link rel="preload" href="/assets/style-CanzIRqu.css" as="style"><link rel="stylesheet" href="/assets/style-CanzIRqu.css">
    <link rel="modulepreload" href="/assets/app-CfmcAgla.js"><link rel="modulepreload" href="/assets/Pytorch 入门(2).html-WTECzw47.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-DmsEaFWH.js" as="script"><link rel="prefetch" href="/assets/intro.html-DE4vB--r.js" as="script"><link rel="prefetch" href="/assets/数据结构入门(1).html-9umBi-Tg.js" as="script"><link rel="prefetch" href="/assets/Goldendict 没声音.html-PVoggauM.js" as="script"><link rel="prefetch" href="/assets/Photoshop 中文改英文以及字体变大.html-BUH3Euh4.js" as="script"><link rel="prefetch" href="/assets/PicList 3.0.4 更新.html-CVS0v9ts.js" as="script"><link rel="prefetch" href="/assets/pnpm 更新后 github 博客更新失败.html-BzMwZUL_.js" as="script"><link rel="prefetch" href="/assets/中期检查要求.html--xKA7hwj.js" as="script"><link rel="prefetch" href="/assets/写作前准备与学术规范.html-FR-PAtla.js" as="script"><link rel="prefetch" href="/assets/学位论文写作.html-CEqEcaWm.js" as="script"><link rel="prefetch" href="/assets/学术论文写作.html-DbEpsgpY.js" as="script"><link rel="prefetch" href="/assets/开题报告要求.html-kX7TOfmQ.js" as="script"><link rel="prefetch" href="/assets/最优化方法(1).html-CSE4Yjqs.js" as="script"><link rel="prefetch" href="/assets/CSS 入门.html-qDoTO6M7.js" as="script"><link rel="prefetch" href="/assets/HTML 入门-上.html-C5wH256_.js" as="script"><link rel="prefetch" href="/assets/HTML 入门-下.html-BWuIhAXA.js" as="script"><link rel="prefetch" href="/assets/JavaScript 5 入门.html-CETAaafm.js" as="script"><link rel="prefetch" href="/assets/Markdown 入门.html-CQB2WkHJ.js" as="script"><link rel="prefetch" href="/assets/Python 入门(1).html-CujvkdHP.js" as="script"><link rel="prefetch" href="/assets/Python 入门(2).html-BQhXoNXN.js" as="script"><link rel="prefetch" href="/assets/Pytorch 入门(1).html-C31J2oba.js" as="script"><link rel="prefetch" href="/assets/关于“xx 入门”.html-BhrW3S0I.js" as="script"><link rel="prefetch" href="/assets/Git 入门(1).html-PvUGqKQc.js" as="script"><link rel="prefetch" href="/assets/Emacs 主题 Spacemacs.html-g7HeEpJ8.js" as="script"><link rel="prefetch" href="/assets/Emacs 入门(1).html-DIHzbKie.js" as="script"><link rel="prefetch" href="/assets/Emacs 入门(2).html-CIYcY5UI.js" as="script"><link rel="prefetch" href="/assets/Evil vim 下的 Spacemacs.html-BtkDsTTs.js" as="script"><link rel="prefetch" href="/assets/Goldendict 设置黑夜模式.html-QRx8rse2.js" as="script"><link rel="prefetch" href="/assets/Zotero 初见.html-D8AlBRVn.js" as="script"><link rel="prefetch" href="/assets/Zotero 插件配置.html-Coop2ZWz.js" as="script"><link rel="prefetch" href="/assets/404.html-CJ1xC1RA.js" as="script"><link rel="prefetch" href="/assets/index.html-DUCwGAJv.js" as="script"><link rel="prefetch" href="/assets/index.html-C5-GMNJQ.js" as="script"><link rel="prefetch" href="/assets/index.html-BAgpgmsL.js" as="script"><link rel="prefetch" href="/assets/index.html-CT6cE8mo.js" as="script"><link rel="prefetch" href="/assets/index.html-CDZHSebC.js" as="script"><link rel="prefetch" href="/assets/index.html-CsbhadJr.js" as="script"><link rel="prefetch" href="/assets/index.html-moXEXJDQ.js" as="script"><link rel="prefetch" href="/assets/index.html-Cq7JKvKu.js" as="script"><link rel="prefetch" href="/assets/index.html-W9oz4F6j.js" as="script"><link rel="prefetch" href="/assets/index.html-kXdIg1MA.js" as="script"><link rel="prefetch" href="/assets/index.html-K05w_11D.js" as="script"><link rel="prefetch" href="/assets/index.html-BE3gRtDi.js" as="script"><link rel="prefetch" href="/assets/index.html-DhMShRT3.js" as="script"><link rel="prefetch" href="/assets/index.html-B59Opd51.js" as="script"><link rel="prefetch" href="/assets/index.html-C4Bl2id6.js" as="script"><link rel="prefetch" href="/assets/index.html-CqA9POIo.js" as="script"><link rel="prefetch" href="/assets/index.html-DIsv6U8I.js" as="script"><link rel="prefetch" href="/assets/index.html-DG-I4rAf.js" as="script"><link rel="prefetch" href="/assets/index.html-By4o_11V.js" as="script"><link rel="prefetch" href="/assets/index.html-KsGlvfGp.js" as="script"><link rel="prefetch" href="/assets/index.html-BwlvBHVY.js" as="script"><link rel="prefetch" href="/assets/index.html-OvnSNrOV.js" as="script"><link rel="prefetch" href="/assets/index.html-CcbfILf8.js" as="script"><link rel="prefetch" href="/assets/index.html-CmF-zBzw.js" as="script"><link rel="prefetch" href="/assets/index.html-DLDe_n8B.js" as="script"><link rel="prefetch" href="/assets/index.html-Cit_lvAb.js" as="script"><link rel="prefetch" href="/assets/index.html-Bp0VflSq.js" as="script"><link rel="prefetch" href="/assets/index.html-cQkotPF8.js" as="script"><link rel="prefetch" href="/assets/index.html-CKsbviN0.js" as="script"><link rel="prefetch" href="/assets/index.html-BCs4lugT.js" as="script"><link rel="prefetch" href="/assets/index.html-CT8TCpEI.js" as="script"><link rel="prefetch" href="/assets/index.html-BXumuAbm.js" as="script"><link rel="prefetch" href="/assets/index.html-Cfbxi4ji.js" as="script"><link rel="prefetch" href="/assets/index.html-D_t66OgY.js" as="script"><link rel="prefetch" href="/assets/index.html-DUwcb1m7.js" as="script"><link rel="prefetch" href="/assets/index.html-D_h6pc4Q.js" as="script"><link rel="prefetch" href="/assets/index.html-CAjkWP04.js" as="script"><link rel="prefetch" href="/assets/index.html-CH6hpSKC.js" as="script"><link rel="prefetch" href="/assets/index.html-Cs_RxntU.js" as="script"><link rel="prefetch" href="/assets/index.html-BWfC-J5R.js" as="script"><link rel="prefetch" href="/assets/index.html-wSQDTSRz.js" as="script"><link rel="prefetch" href="/assets/index.html-poH0RgBV.js" as="script"><link rel="prefetch" href="/assets/index.html-CF_MpIbi.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/index-BrzB_qDf.js" as="script"><link rel="prefetch" href="/assets/giscus-BACEvYzX.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="带我回家"><img class="vp-nav-logo" src="https://vip.123pan.cn/1844935313/obsidian/blog-logo.jpg" alt><!----><span class="vp-site-name hide-in-pad">庸碌无常的博客</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/bug/" aria-label="问题"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:laptop-code" sizing="height" height="1em"></iconify-icon><!--]-->问题<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/tools/" aria-label="工具"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" sizing="height" height="1em"></iconify-icon><!--]-->工具<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/pluinyiasnhg/pluinyiasnhg.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-appearance-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-appearance-dropdown"><!----></div></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="主页"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:house" sizing="both" width="1em" height="1em"></iconify-icon><!--]-->主页<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Bug</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Course</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">CS Basic</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Programming Languagae</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/CSS%20%E5%85%A5%E9%97%A8.html" aria-label="CSS 入门"><!---->CSS 入门<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/HTML%20%E5%85%A5%E9%97%A8-%E4%B8%8A.html" aria-label="HTML 入门-上"><!---->HTML 入门-上<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/HTML%20%E5%85%A5%E9%97%A8-%E4%B8%8B.html" aria-label="HTML 入门-下"><!---->HTML 入门-下<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/JavaScript%205%20%E5%85%A5%E9%97%A8.html" aria-label="JavaScript 5 入门"><!---->JavaScript 5 入门<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/Markdown%20%E5%85%A5%E9%97%A8.html" aria-label="Markdown 入门"><!---->Markdown 入门<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/Python%20%E5%85%A5%E9%97%A8(1).html" aria-label="Python 入门(1)"><!---->Python 入门(1)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/Python%20%E5%85%A5%E9%97%A8(2).html" aria-label="Python 入门(2)"><!---->Python 入门(2)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/programming%20languagae/Pytorch%20%E5%85%A5%E9%97%A8(1).html" aria-label="Pytorch 入门(1)"><!---->Pytorch 入门(1)<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/programming%20languagae/Pytorch%20%E5%85%A5%E9%97%A8(2).html" aria-label="Pytorch 入门(2)"><!---->Pytorch 入门(2)<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Thought</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Tools</span><span class="vp-arrow end"></span></button><!----></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Pytorch 入门(2)</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://pluinyiasnhg.top" target="_blank" rel="noopener noreferrer">庸碌无常</a></span><span property="author" content="庸碌无常"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025/10/14</span><meta property="datePublished" content="2025-10-14T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 15 分钟</span><meta property="timeRequired" content="PT15M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color6 clickable" role="navigation">Python</span><!--]--><meta property="articleSection" content="Python"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color1 clickable" role="navigation">Pytorch</span><span class="page-tag-item color3 clickable" role="navigation">尚硅谷</span><!--]--><meta property="keywords" content="Pytorch,尚硅谷"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><h1 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h1><p>学习尚硅谷的 <a href="https://www.bilibili.com/video/BV1k44LzPEhU" target="_blank" rel="noopener noreferrer">NLP 教程</a>。</p><!-- more --><h1 id="技术演进历史" tabindex="-1"><a class="header-anchor" href="#技术演进历史"><span>技术演进历史</span></a></h1><p>90 年代，随着计算能力的提升和语料资源的积累，统计方法逐渐成为主流。通过对大量文本数据进行概率建模，系统能够“学习”语言中的模式和规律。典型方法包括 n-gram 模型、隐马尔可夫模型(HMM)和最大熵模型。</p><p>进入 21 世纪，NLP 技术逐步引入传统机器学习方法，如逻辑回归、支持向量机 (SVM)、决策树、条件随机场(CRF)等。这些方法在命名实体识别、文本分类等任务上表现出色。在此阶段，特征工程成为关键环节，研究者需要设计大量手工特征来提升模型性能。</p><p>自2010年开始，深度学习在NLP中迅速崛起。基于神经网络的模型，比如 RNN、LSTM、GRU等，取代了传统手工特征工程，能够从海量数据中自动提取语义表示。随后，Transformer 架构的提出极大提升了语言理解与生成的能力，深度学习不仅在精度上实现突破，也推动了预训练语言模型（如GPT、BERT等）和迁移学习的发展，使 NLP 技术更通用、更强大。</p><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251014224728382.png" alt="RNN" tabindex="0" loading="lazy"><figcaption>RNN</figcaption></figure><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251014224924676.png" alt="LSTM（Long Short-Term Memory）" tabindex="0" loading="lazy"><figcaption>LSTM（Long Short-Term Memory）</figcaption></figure><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251014224958375.png" alt="GRU（Gated Recurrent Unit）" tabindex="0" loading="lazy"><figcaption>GRU（Gated Recurrent Unit）</figcaption></figure><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251014225051167.png" alt="Transformer" width="438" tabindex="0" loading="lazy"><figcaption>Transformer</figcaption></figure><h1 id="安装所需依赖" tabindex="-1"><a class="header-anchor" href="#安装所需依赖"><span>安装所需依赖</span></a></h1><p>该课程使用的 Python 版本是 3.12。安装所需依赖有：</p><ul><li><code>pytorch</code>：深度学习框架，主要用于模型的构建、训练与推理。</li><li><code>jieba</code>：高效的中文分词工具，用于对原始中文文本进行分词预处理。</li><li><code>gensim</code>：用于训练词向量模型（如 Word2Vec、FastText），提升模型对词语语义关系的理解。可以使用<a href="https://github.com/Embedding/Chinese-Word-Vectors" target="_blank" rel="noopener noreferrer">公开的中文词向量</a></li><li><code>transformers</code>：由 Hugging Face 提供的预训练模型库，用于加载和微调 BERT 等主流模型。</li><li><code>datasets</code>：Hugging Face 提供的数据处理库，用于高效加载和预处理大规模数据集。</li><li><code>tensorboard</code>：可视化工具，用于展示训练过程中的损失函数、准确率等指标变化。</li><li><code>tqdm</code>：用于显示进度条，帮助实时监控训练与数据处理的进度。</li><li><code>Jupyter Notebook</code>：交互式开发环境，用于编写、测试和可视化模型代码与实验过程。</li><li><code>scikit-learn</code> ：机器学习工具。可以用来划分数据集。</li></ul><h1 id="文本表示方法" tabindex="-1"><a class="header-anchor" href="#文本表示方法"><span>文本表示方法</span></a></h1><p>文本表示是将自然语言转化为计算机能够理解的数值形式。</p><p>早期的文本表示方法（如词袋模型）通常将整段文本编码为一个向量。这类方法实现简单、计算高效，但存在明显的局限性——表达语序和上下文语义的能力较弱。</p><p>因此，现代 NLP 技术逐渐引入更加精细和表达力更强的文本表示方法，以更有效地建模语言的结构和含义：</p><ul><li>分词（Tokenization）是将原始文本切分为若干具有独立语义的最小单元，即 <code>token</code> 的过程，是所有 NLP 任务的起点</li><li>词表（Vocabulary）是由语料库构建出的、包含模型可识别 token 的集合。词表中每个 token 都分配有唯一的 <code>ID</code>，并支持 token 与 ID 之间的双向映射</li><li>词向量：在训练或预测过程中，模型会首先对输入文本进行分词，再通过词表将每个 token 映射为其对应的 ID。接着，这些 ID 会被输入嵌入层，转换为<strong>低维稠密的向量表示</strong>，也就是词向量。ID 可以用 one-hot 向量表示，通过与词表进行矩阵乘法，抽出对应的词向量</li></ul><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251015203201267.png" alt="文本分词和构建词表" width="600" tabindex="0" loading="lazy"><figcaption>文本分词和构建词表</figcaption></figure><p>在文本生成任务中，模型的输出层会针对词表中的每个 token 生成一个概率分布，表示其作为下一个词的可能性。系统通常选取具有最大概率的ID，并通过词表查找对应的 token，从而逐步生成最终的输出文本。下图中输入文本为“我想”，该文本的下一个词概率明显较大的有“你”、“吃”、“去”，即“我想你”、“我想吃”、“我想去”。</p><p>这一过程很像是在查字典，拿到一个句子，里面有一些不认识的单词，识别出陌生单词的行为就是分词。通过单词查询字典对应条目所在的页数，页数即为 ID。通过页码查看该单词详细的释义，释义即是词向量。字典的解释总是比单词要多上许多内容，模型通过这些内容进而更好的理解陌生单词，从而把握整句话的含义。</p><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251015203535035.png" alt="文本生成任务，预测下一个词" width="600" tabindex="0" loading="lazy"><figcaption>文本生成任务，预测下一个词</figcaption></figure><p>词向量有静态与动态之分。静态词向量只为每个词分配一个<strong>固定的向量表示</strong>，不论它在句中出现的语境如何。然而，语言的表达极其灵活，一个词在不同上下文中可能有完全不同的含义。这就推动了上下文相关的词表示的发展。上下文相关词表示（Contextual Word Representations），是指词语的向量表示会根据它所在的句子上下文动态变化，从而更好地捕捉其语义。一个具有代表性的模型是——<a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener noreferrer">ELMo</a>。</p><h2 id="英文分词" tabindex="-1"><a class="header-anchor" href="#英文分词"><span>英文分词</span></a></h2><p>按照分词粒度的大小，可分为词级（Word-Level）分词、字符级（Character‑Level）分词和子词级（Subword‑Level）分词。</p><p>英语的词级分词按照空格和标点分隔词语，这种分词虽然便于理解和实现，但在实际应用中容易出现 OOV（Out‑Of‑Vocabulary）问题。所谓 OOV，是指在模型使用阶段，输入文本中出现了不在预先构建词表中的词语，常见的有网络热词、专有名词、复合词及拼写变体等。由于模型无法识别这些词，通常会将其统一替换为特殊标记，如 <code>&lt;UNK&gt;</code>（Unknown Token），从而导致语义信息的丢失，影响模型的理解与预测能力。</p><p>字符级分词是以单个字符为最小单位进行分词的方法，文本中的每一个字母、数字、标点甚至空格，都会被视作一个独立的 token。在这种分词方式下，词表仅由所有可能出现的字符组成，因此词表规模非常小，覆盖率极高，几乎不存在 OOV问题。然而，由于单个字符本身语义信息极弱，模型必须依赖更长的上下文来推断词义和结构，这显著增加了建模难度和训练成本。此外，输入序列也会变得更长，影响模型效率。</p><p>子词级分词是一种介于词级分词与字符级分词之间的分词方法，它将词语切分为更小的单元——子词（subword），例如词根、前缀、后缀或常见词片段。与词级分词相比，子词分词可以显著缓解OOV问题；与字符级分词相比，它能更好地保留一定的语义结构。</p><h2 id="中文分词" tabindex="-1"><a class="header-anchor" href="#中文分词"><span>中文分词</span></a></h2><p>类似英文分词，中文分词也能按照三个等级进行划分：</p><ul><li>字符级分词：一个汉字作为一个 token</li><li>词级分词：一个词语作为一个 token。由于中文词语不像英文那样可以用空格进行区分，所以需要依赖词典、规则或模型来识别词语边界</li><li>子词级分词：以汉字为基本单位，通过学习语料中高频的字组合（如“自然”、“语言”、“处理”），自动构建子词词表</li></ul><p>中文分词工具，按照实现方式分为如下两类：</p><ul><li>一类是基于<strong>词典或模型</strong>的传统方法，主要以“词”为单位进行切分。比如 <a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener noreferrer">jieba</a>、<a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener noreferrer">HanLP</a></li><li>另一类是基于<strong>子词建模算法</strong>（如BPE）的方式，从数据中自动学习高频字组合，构建子词词表。比如 <a href="https://github.com/huggingface/tokenizers" target="_blank" rel="noopener noreferrer">Hugging Face Tokenizer</a>、<a href="https://github.com/google/sentencepiece" target="_blank" rel="noopener noreferrer">SentencePiece</a>、<a href="https://github.com/openai/tiktoken" target="_blank" rel="noopener noreferrer">tiktoken</a></li></ul><h1 id="rnn" tabindex="-1"><a class="header-anchor" href="#rnn"><span>RNN</span></a></h1><p>RNN（循环神经网络）的核心结构是一个具有循环连接的隐藏层，它以时间步（time step）为单位，依次处理输入序列中的每个 token。</p><p>在每个时间步，RNN 接收当前 token 的向量和上一个时间步的隐藏状态（即隐藏层的输出），计算并生成新的隐藏状态，并将其传递到下一时间步。其公式为：</p><p>$$h_t=tanh(x_tW_x+h_{t-1}W_h+b)$$</p><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251101095651999.png" alt="RNN 的 seqlen、input_size、hidden_size" width="650" tabindex="0" loading="lazy"><figcaption>RNN 的 seqlen、input_size、hidden_size</figcaption></figure><ul><li><code>seq_len</code> 为4，即从 $x_1$ 到 $x_4$ ，是序列长度</li><li><code>input_size</code> 为3，即每个 $x_t$ 的长度，是每个时间步输入特征的维度（词向量维度）</li><li><code>hidden_size</code> 为4，即图中右侧的四个圆。</li></ul><h2 id="单层结构" tabindex="-1"><a class="header-anchor" href="#单层结构"><span>单层结构</span></a></h2><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251101100158825.png" alt="单层结构 RNN" width="650" tabindex="0" loading="lazy"><figcaption>单层结构 RNN</figcaption></figure><p>注意，图中单层结构 RNN 展开后有4个包含激活函数 tanh 的层，但实际上他们是共用一个层。</p><h2 id="多层结构" tabindex="-1"><a class="header-anchor" href="#多层结构"><span>多层结构</span></a></h2><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251101100354469.png" alt="多层结构 RNN" width="650" tabindex="0" loading="lazy"><figcaption>多层结构 RNN</figcaption></figure><p>图中形如 $h_0^1$ 的符号，其下标表示时间步，上标表示 RNN 的层数。如果把图中右侧的展开图视为一个原点在左下角的平面坐标系，那么坐标系的 x 轴是时间步，y 轴是层数。</p><h2 id="双向结构" tabindex="-1"><a class="header-anchor" href="#双向结构"><span>双向结构</span></a></h2><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251101100809508.png" alt="双向结构 RNN" width="650" tabindex="0" loading="lazy"><figcaption>双向结构 RNN</figcaption></figure><p>前面提到的 RNN 都是单向结构的，在每个时间步只输出一个隐藏状态，该状态仅包含来自上文的信息。为了充分利用当前词之后的下文，即利用上下文内容，人们设计了双向结构的 RNN，反映在上图中就是，有两个方向的箭头：一个从左侧进入激活函数 tanh，一个从右侧进入激活函数 tanh。不过两个 tanh 所在的层不是同一个，出于训练效率的考虑，正向和逆向的两个层应该并行训练。</p><p>最后，正向 RNN 和 逆向 RNN 通过简单的拼接（concat）作为下一层的输入，如果 RNN 是多层结构。</p><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251101143912603.png" alt="input、output、h_n 的形状" tabindex="0" loading="lazy"><figcaption>input、output、h_n 的形状</figcaption></figure><h1 id="rnn-实践" tabindex="-1"><a class="header-anchor" href="#rnn-实践"><span>RNN 实践</span></a></h1><h2 id="数据集处理" tabindex="-1"><a class="header-anchor" href="#数据集处理"><span>数据集处理</span></a></h2><p>数据集下载地址：<a href="https://huggingface.co/datasets/Jax-dan/HundredCV-Chat" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/Jax-dan/HundredCV-Chat</a>。也可以从 huggingface 的镜像地址下载：<a href="https://hf-mirror.com/datasets/Jax-dan/HundredCV-Chat" target="_blank" rel="noopener noreferrer">https://hf-mirror.com/datasets/Jax-dan/HundredCV-Chat</a>。</p><p>数据集文件的格式为 <code>.jsonl</code>，<code>jsonl</code> 文件的每一行可以看作一个 <code>json</code> 文件，下面代码来自数据集文件的第一行。本任务中只需用到数据集中的对话文本。</p><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-json"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">{</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    &quot;topic&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;校园生活分享&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    &quot;user1&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;李欣怡&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    &quot;user2&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;杨欢&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    &quot;dialog&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: [</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：杨欢，最近校园里有什么新鲜事吗？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：嗨，李欣怡！我们学校刚刚举办了一次科技节，很多学生展示了他们的发明。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：听起来好有趣！我这边的学校正在筹备一场文化节，主要是推广传统文化。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：文化节听起来也很棒。你们会做哪些活动呢？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：我们打算办个书法展和传统服饰秀，还会请来一些老师教大家制作传统小吃。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：真不错！我们科技节上有同学展示了一款智能垃圾分类箱，挺受欢迎的。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：这创意真好。我们也应该多关注环保问题，比如组织一次清洁校园的活动。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：对，我也觉得这样做很有意义。你们学校有类似的社团或小组吗？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：有的，我们有一个志愿者服务队，经常会组织这样的活动。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：那真是太好了！你平时是怎么平衡学业和这些课外活动的呢？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：我会合理安排时间，把学习放在第一位，然后是重要的活动。你觉得呢？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：我也是这样做的。我觉得找到自己的兴趣点很重要，这样才能更有动力去做好每一件事。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：完全同意！对了，你参加过模拟联合国社团吗？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：参加过，挺有意思的。你呢？有没有类似的经历？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：有啊！我还当过中国代表团的代表，提出了很多关于可持续发展的建议。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：真厉害！你在这些活动中一定学到了不少东西吧？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：当然了，不仅增长见识还锻炼了我的团队合作能力。你也一样吧？&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：是的，我也从中受益匪浅，特别是编程能力和解决问题的能力得到了提升。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user1：希望以后我们能有更多机会一起交流学习经验。&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;user2：绝对同意！我们可以互相分享更多的校园活动信息和心得。&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>为了构造适用于“下一词预测”任务的训练样本，首先需要对原始语料进行分词。随后，采用<strong>滑动窗口</strong>的方式，从分词后的序列中提取连续的上下文片段，并以每个窗口的下一个词作为预测目标，构成输入-输出对，如下图所示：</p><figure><img src="https://vip.123pan.cn/1844935313/obsidian/20251101155736341.png" alt="用上文的5个词预测下一个词" width="400" tabindex="0" loading="lazy"><figcaption>用上文的5个词预测下一个词</figcaption></figure><h2 id="模型结构设计" tabindex="-1"><a class="header-anchor" href="#模型结构设计"><span>模型结构设计</span></a></h2><p>本任务采用基于 RNN 的语言模型结构来实现“下一词预测”功能。模型整体由以下三个主要部分组成：</p><ol><li>嵌入层。将输入的词或字索引映射为稠密向量表示，便于后续神经网络处理。</li><li>RNN。用于建模输入序列的上下文信息，输出最后一个时间步的隐藏状态作为上下文表示。</li><li>输出层。这里是线性层，将隐藏状态映射到词表大小的维度，生成对下一个词的概率预测。</li></ol><h2 id="训练方案" tabindex="-1"><a class="header-anchor" href="#训练方案"><span>训练方案</span></a></h2><ul><li>损失函数选择 CrossEntropyLoss。预测下一词功能，可以看作多分类问题</li><li>优化器选择 Adam</li></ul><h2 id="项目结构" tabindex="-1"><a class="header-anchor" href="#项目结构"><span>项目结构</span></a></h2><div class="language-zsh line-numbers-mode" data-highlighter="shiki" data-ext="zsh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-zsh"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">input_method</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> data</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">              # 数据目录</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> processed</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">     # 预处理后的数据</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">│  </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> └──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> raw</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">           # 原始数据</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> logs</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">              # 训练日志</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> models</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">            # 保存训练好的模型参数</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">└──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> src</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">               # 源码目录</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">     # 超参数配置</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dataset.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 自定义Dataset</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> evaluate.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">   # 模型评估脚本，存放评价指标</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> model.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">      # 模型结构定义</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> predict.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 模型推理脚本</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> process.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 数据预处理脚本</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    ├──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> tokenizer.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 自定义分词器</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">    └──</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> train.py</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">      # 模型训练脚本</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pandas </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">CURRENT_DIR</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">dirname</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">abspath</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">__file__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> process</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;开始处理数据&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 1.读取文件</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    jsonl_path </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> os.path.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">join</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">CURRENT_DIR</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;../data/raw/synthesized_.jsonl&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    df </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">read_json</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(jsonl_path, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">lines</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">orient</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;records&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">head</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">())</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    </span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;数据处理完成&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;__main__&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">    process</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>词表基于训练集构建，<br> 需要额外添加一个 <code>&lt;UNK&gt;</code> ，<br> 词表必须有序。<br> 词表保存在 <code>models</code> 目录下，和模型参数放一个地方。<br> 词表中每一行是一个 ID，ID 之间用换行符分隔，可以视为一个大字符串，字符之间用 <code>\n</code> 分割。<br> 构建词表时，最费时的阶段是给句子分词，可以用 tqdm 显示进度条，以及用 <code>df_sample = df.sample(frac=0.1)</code> 抽样，抽取十分之一的数据。</p><p><a href="http://model.py" target="_blank" rel="noopener noreferrer">model.py</a><br><code>last_hidden_state = output[:, -1, :]</code> 省略掉第二个维度，因为该维度的大小为1</p><p><a href="http://train.py" target="_blank" rel="noopener noreferrer">train.py</a></p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">with</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> open</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(config.</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MODEL_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;vocab.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;r&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">encoding</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;utf-8&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	vocab_list </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">readlines</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vocab_list[:</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-zsh line-numbers-mode" data-highlighter="shiki" data-ext="zsh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-zsh"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;unk&gt;\n&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;交通管理\n&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;福音\n&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;RFM\n&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;钉\n&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>tensorboard 可以实时检测训练过程。<br> 通过设置层级目录，tensorboard 可以在一张图上显示多次实验的结果，用来进行比较</p><p><a href="http://predict.py" target="_blank" rel="noopener noreferrer">predict.py</a></p><p><code>input_tensor = torch.tensor([indexs], dtype=torch.long).to(device)</code> 这里的 <code>[]</code> 用于增加一个维度，使张量形状从 <code>[seq_len]</code> 变为 <code>[1, seqlen]</code><br> 预测脚本的模拟应用：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> predict</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">text</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 1. 设备</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    device </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;cuda&quot;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.cuda.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">is_available</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">else</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;cpu&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 2. 词表</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    with</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> open</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(config.</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">MODEL_PATH</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> /</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;vocab.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;r&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">encoding</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;utf-8&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        vocab_list </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [line.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">strip</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">\n</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> line </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> f.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">readlines</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    word2index </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {word: index </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> index, word </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> enumerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vocab_list)}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    index2word </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {index: word </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> index, word </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> enumerate</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vocab_list)}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 3. 模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> InputMethodModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">vocab_size</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">len</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(vocab_list)).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(device)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 4. 处理输入</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> jieba.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">lcut</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(text)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    indexs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [word2index.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">get</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(token, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> token </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tokens]</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # input_tensor = torch.tensor(indexs, dtype=torch.long).unsqueeze(0)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    input_tensor </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">([indexs], </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.long).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(device)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    </span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 5. 预测逻辑</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">eval</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    with</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">no_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        output </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(input_tensor)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # output.shape: [batch_size, vocab_size]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    top5_indexes </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">topk</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(output, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">k</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).indices</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # top5_indexes.shape: [batch_size, 5]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    top5_indexes_list </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> top5_indexes.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tolist</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    top5_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  [index2word.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">get</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(index) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> index </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> top5_indexes_list[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]]</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> top5_tokens</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;__main__&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    top5_tokens </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> predict</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;我们团队&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">    print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(top5_tokens)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><a href="http://evaluate.py" target="_blank" rel="noopener noreferrer">evaluate.py</a></p><p><code>evaluate</code> 函数有调用 <code>predict.py</code> 中 <code>predict_batch</code> 函数，后者里面已经有 <code>model.eval()</code> 和 <code>with torch.no_grad():</code> ，所以 <code>evaluate</code> 函数开头两行不用写这两句。</p><p><code>target = target.tolist()</code> ：该评估脚本不需要计算损失，因此 <code>target</code> 也不用放到 gpu 上。</p><p>pytorch 中 <code>topk</code> 默认按从大到小排序</p><p><a href="http://tokenizer.py" target="_blank" rel="noopener noreferrer">tokenizer.py</a></p><p>将词表操作相关的代码抽取出来，放到 <code>tokenizer.py</code> 中。</p><p>对象 JiebaTokenizer：</p><p>属性：</p><ul><li><code>vocab_list</code> : <code>list[str]</code> 词表列表</li><li><code>vocab_size</code> : <code>int</code> 词表大小</li><li><code>word2index</code> : <code>dict[str, int]</code> word 到 index 的映射</li><li><code>index2word</code> : <code>dict[int, str]</code> index 到 word 的映射</li><li><code>unk_token</code> : <code>str</code> 未登录词，比如 <code>&lt;unk&gt; &lt;begin&gt; &lt;end&gt;</code> ，这是个类属性</li><li><code>unk_token_index</code> : <code>int</code> 未登录词 index</li></ul><p>方法：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">@</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">staticmethod</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> tokenize</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">sentence</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span><span style="--shiki-light:#986801;--shiki-dark:#ABB2BF;"> Any</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) -&gt; list[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">分词 </span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">将 jieba.lcut() 封装到列表中</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:parma sentence: 句子</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:return: token列表</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">@</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">classmethod</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> build_vocab</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">cls</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">				sentence: list[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">],</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">				vocab_file: Any)</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">构建并保存词表</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:parma sentence: 句子</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:parma vocab_file: 词表文件路径</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">@</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">classmethod</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> from_vocab</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">cls</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, vocab_file: Any) </span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">-&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> JiebaTokenizer</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">加载词表并构建Tokenizer对象</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">构造方法，封装了 __init_()，使用起来更方便</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:parma vocab_file: 词表文件</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:return: tokenizer对象</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, vocab_list: list[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">str</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]) </span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">-&gt;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> None</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">初始化tokenizer</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:parma vocab_list: 词表列表</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> encode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, sentence: Any) </span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">-&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> list[</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">编码</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">相当于把分词方法 tokenize 和属性 word2index 合二为一</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:parma sentence: 句子</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">:return: index列表</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>build_vocab</code> 是一个类方法，因为创建 <code>JiebaTokenizer</code> 类时需要传入词表，创建词表的方法 <code>build_vocab</code> 需要先实例化 <code>JiebaTokenizer</code> 。如果把 <code>build_vocab</code> 设置为静态方法，那么它就无法使用 <code>self</code> 获取 <code>unk_token</code> 。设置为类方法后，<code>build_token</code> 也没法用 self 获取 unk_token，这时把 unk_token 设置为类属性。</p><p>实例方法 类方法 静态方法</p></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/pluinyiasnhg/pluinyiasnhg.github.io/edit/main/src/programming languagae/Pytorch 入门(2).md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">最近更新</span><time class="vp-meta-info" datetime="2025-11-16T07:10:09.000Z" data-allow-mismatch>2025/11/16 07:10</time></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: pluinyiasnhg@gmail.com">pluinyiasnhg</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/programming%20languagae/Pytorch%20%E5%85%A5%E9%97%A8(1).html" aria-label="Pytorch 入门(1)"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->Pytorch 入门(1)</div></a><!----></nav><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer"><p>Served by GitHub Pages</p></div><div class="vp-copyright">Copyright © 2025 庸碌无常 CC 4.0 Licensed</div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CfmcAgla.js" defer></script>
  </body>
</html>
